import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search
import torch

st.set_page_config(page_title="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑ –§–õ", layout="centered")
st.title("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑")

# ---------------- DATA ----------------
@st.cache_data
def get_data():
    return load_all_excels()

df = get_data()

# ---------------- TOPICS ----------------
def normalize_topic(t: str) -> str:
    return t.strip().lower()

# –º–∞–ø–∞: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è ‚Üí –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è (–∫—Ä–∞—Å–∏–≤–∞—è)
topic_display_map = {}
for topics in df["topics"]:
    for topic in topics:
        norm = normalize_topic(topic)
        if norm not in topic_display_map:
            topic_display_map[norm] = topic.strip()

# —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–º–∞—Ç–∏–∫–∏
all_topics_norm = sorted(topic_display_map.keys())

# ---------------- TABS ----------------
tab1, tab2, tab3 = st.tabs(["üîç –ü–æ–∏—Å–∫", "üö´ –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º", "‚úÖ/‚ùå –î–∞ –∏ –ù–µ—Ç"])

# ================= TAB 1 =================
with tab1:
    selected_topics = st.multiselect(
        "–§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º:",
        options=all_topics_norm,
        format_func=lambda t: topic_display_map[t]
    )

    filter_search_by_topics = st.checkbox(
        "–ò—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–µ–º–∞—Ç–∏–∫–∞—Ö",
        value=False
    )

    # -------- –§—Ä–∞–∑—ã –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º --------
    if selected_topics:
        st.markdown("### üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º:")
        shown_phrases = set()
        filtered_df = df[
            df["topics"].apply(
                lambda topics: any(
                    normalize_topic(t) in selected_topics for t in topics
                )
            )
        ]

        for row in filtered_df.itertuples():
            if row.phrase_full in shown_phrases:
                continue
            shown_phrases.add(row.phrase_full)

            topics_pretty = [
                topic_display_map.get(normalize_topic(t), t)
                for t in row.topics
            ]

            with st.container():
                st.markdown(
                    f"""
                    <div style="border:1px solid #e0e0e0;
                                border-radius:12px;
                                padding:16px;
                                margin-bottom:12px;
                                background:#f9f9f9;">
                        <div style="font-size:18px;font-weight:600;">üìù {row.phrase_full}</div>
                        <div style="font-size:14px;color:#666;">
                            üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics_pretty)}</strong>
                        </div>
                    </div>
                    """,
                    unsafe_allow_html=True
                )

                if row.comment and str(row.comment).strip().lower() != "nan":
                    with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"):
                        st.markdown(row.comment)

    # -------- –ü–æ–∏—Å–∫ --------
    query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:")

    if query:
        try:
            search_df = df

            if filter_search_by_topics and selected_topics:
                search_df = df[
                    df["topics"].apply(
                        lambda topics: any(
                            normalize_topic(t) in selected_topics for t in topics
                        )
                    )
                ].copy()

                if search_df.empty:
                    search_df.attrs["phrase_embs"] = torch.empty((0, 384))

            if search_df.empty:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º.")
            else:
                # ----- Semantic -----
                results = semantic_search(query, search_df)

                if results:
                    st.markdown("### üîç –£–º–Ω—ã–π –ø–æ–∏—Å–∫")
                    for score, phrase, topics, comment in results:
                        topics_pretty = [
                            topic_display_map.get(normalize_topic(t), t)
                            for t in topics
                        ]

                        st.markdown(
                            f"""
                            <div style="border:1px solid #e0e0e0;
                                        border-radius:12px;
                                        padding:16px;
                                        margin-bottom:12px;
                                        background:#f9f9f9;">
                                <div style="font-size:18px;font-weight:600;">üß† {phrase}</div>
                                <div style="font-size:14px;color:#666;">
                                    üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics_pretty)}</strong>
                                </div>
                                <div style="font-size:13px;color:#999;">
                                    üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.2f}
                                </div>
                            </div>
                            """,
                            unsafe_allow_html=True
                        )

                        if comment and str(comment).strip().lower() != "nan":
                            with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"):
                                st.markdown(comment)
                else:
                    st.info("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

                # ----- Keyword -----
                exact_results = keyword_search(query, search_df)

                if exact_results:
                    st.markdown("### üß∑ –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫")
                    for phrase, topics, comment in exact_results:
                        topics_pretty = [
                            topic_display_map.get(normalize_topic(t), t)
                            for t in topics
                        ]

                        st.markdown(
                            f"""
                            <div style="border:1px solid #e0e0e0;
                                        border-radius:12px;
                                        padding:16px;
                                        margin-bottom:12px;
                                        background:#f9f9f9;">
                                <div style="font-size:18px;font-weight:600;">üìå {phrase}</div>
                                <div style="font-size:14px;color:#666;">
                                    üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics_pretty)}</strong>
                                </div>
                            </div>
                            """,
                            unsafe_allow_html=True
                        )

                        if comment and str(comment).strip().lower() != "nan":
                            with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"):
                                st.markdown(comment)

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")

# ================= TAB 2 =================
with tab2:
    st.markdown("### üö´ –õ–æ–∫–∞–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ **–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º**")
    unused_topics = [
        "Local_Balance_Transfer", "Local_Friends", "Local_Next_Payment",
        "Local_Order_Cash", "Local_Other_Cashback", "Local_RemittanceStatus",
        "–ü–æ–¥–æ–∂–¥–∏ (Wait)", "Local_X5", "PassportChangeFirst",
        "PassportChangeSecond", "–ú–µ–Ω—å—à–µ (Local_Less)", "–ë–æ–ª—å—à–µ (Local_More)",
        "–†–µ—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥ –∑–∞–ª–æ–≥ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏",
        "–î–µ–π—Å—Ç–≤—É—é—â–∏–π –∑–∞–π–º", "General –ú–æ–∏ –∫—Ä–µ–¥–∏—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
        "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å/–ò–∑–º–µ–Ω–∏—Ç—å/–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å",
        "–ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–º",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ —Å–µ–∫—Ä–µ—Ç–Ω—ã–π –∫–æ–¥",
        "–ù–æ–≤–∞—è –∫–∞—Ä—Ç–∞", "–ü—Ä–æ–±–ª–µ–º–∞ —Å –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ–º –∫—ç—à–±—ç–∫–∞"
    ]
    for t in unused_topics:
        st.markdown(f"- {t}")

# ================= TAB 3 =================
def render_phrases_grid(phrases, cols=3, color="#e0f7fa"):
    rows = [phrases[i:i+cols] for i in range(0, len(phrases), cols)]
    for row in rows:
        columns = st.columns(cols)
        for col, phrase in zip(columns, row):
            col.markdown(
                f"""
                <div style="background:{color};
                            padding:6px 10px;
                            border-radius:12px;
                            margin:4px;
                            font-size:14px;">
                    {phrase}
                </div>
                """,
                unsafe_allow_html=True
            )

with tab3:
    st.markdown("### ‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ ¬´–î–ê¬ª")
    render_phrases_grid(
        [
            "–î–∞", "–ê–≥–∞", "–£–≥—É", "–ú–æ–∂–Ω–æ", "–ì–æ—Ç–æ–≤",
            "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ", "–†–∞—Å—Å–∫–∞–∂–∏", "–°–∫–∞–∂–∏", "–ü—Ä–æ–≤–µ—Ä—å"
        ],
        color="#d1f5d3"
    )

    st.markdown("### ‚ùå –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ ¬´–ù–ï–¢¬ª")
    render_phrases_grid(
        ["–ù–µ –Ω–∞–¥–æ", "–ù–µ —Ö–æ—á—É", "–ù–µ –≥–æ—Ç–æ–≤", "–ù–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ"],
        color="#f9d6d5"
    )
